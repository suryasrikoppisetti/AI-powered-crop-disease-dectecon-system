{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suryasrikoppisetti/AI-powered-crop-disease-dectecon-system/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "H5HY2H4ODYPt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Define dataset paths\n",
        "dataset_dir = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset\"\n",
        "train_dir = os.path.join(dataset_dir, \"train\")\n",
        "valid_dir = os.path.join(dataset_dir, \"validation\")\n",
        "\n",
        "# Image properties\n",
        "img_size = (150, 150)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqPj131fDuEp",
        "outputId": "e7955841-4670-4890-bf02-c93d7668fae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2294 images belonging to 3 classes.\n",
            "Found 1112 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation & Preprocessing\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load training images\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "# Load validation images\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"categorical\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "YH3lHLYxDyzx",
        "outputId": "a4ab8831-9bf9-4f35-c20e-02ccc60c8a21"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">82944</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">10,616,960</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m82944\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m10,616,960\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,636,739</span> (40.58 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,636,739\u001b[0m (40.58 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,636,739</span> (40.58 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,636,739\u001b[0m (40.58 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Build the CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nps1zHVREE-m",
        "outputId": "534fa483-0fa0-4b94-e8b5-044b58d92f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.9996 - loss: 0.0081 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
            "Epoch 2/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - accuracy: 0.9918 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
            "Epoch 3/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.9974 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 4.0266e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 2s/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 3.5513e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.9991 - val_loss: 0.0012\n",
            "Epoch 6/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.9978 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 8.4660e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 2s/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
            "Epoch 8/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 2s/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 1.0000 - val_loss: 2.8758e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 2s/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 7.6182e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 1.4077e-04\n"
          ]
        }
      ],
      "source": [
        "epochs = 10  # Adjust as needed\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=valid_generator,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOUYuCjcKHTR",
        "outputId": "2395e5a8-bbba-4bd6-c064-7682f193433c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model training completed and saved successfully!\n"
          ]
        }
      ],
      "source": [
        "model.save(\"/content/drive/MyDrive/under leaf spots/crop_disease_model.keras\")\n",
        "print(\"✅ Model training completed and saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJSBYJd_YgXO",
        "outputId": "3964c9a6-629f-458f-b87b-af15d091fa8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model_path = \"/content/drive/MyDrive/under leaf spots/crop_disease_model.keras\"\n",
        "model = load_model(model_path)\n",
        "\n",
        "print(\"✅ Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNR_SSmzY09j",
        "outputId": "1ee03cbf-cbe1-4907-d62d-a211590134ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Image preprocessed successfully!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Path to the new image\n",
        "image_path = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset/train/potato/late blight/0051e5e8-d1c4-4a84-bf3a-a426cdad6285___RS_LB 4640.JPG\"  # Change the file name\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = image.load_img(image_path, target_size=(150, 150))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match batch format\n",
        "img_array = img_array / 255.0  # Normalize the image\n",
        "\n",
        "print(\"✅ Image preprocessed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjtdglq6cA7t",
        "outputId": "963ed054-52cd-44c1-8f54-d73a1a5e4e5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded successfully!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
            "✅ Predicted Disease: potato_late_blight\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ✅ Step 1: Load the Trained Model\n",
        "model_path = \"/content/drive/MyDrive/under leaf spots/crop_disease_model.keras\"\n",
        "model = load_model(model_path)\n",
        "print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "# ✅ Step 2: Define Class Labels Manually (based on your dataset)\n",
        "class_labels = [\"potato_late_blight\", \"rice_LeafBLast\", \"tomato_target_spot\"]  # Update as per your training data\n",
        "\n",
        "# ✅ Step 3: Function to Predict Disease\n",
        "def predict_disease(image_path):\n",
        "    # Load and preprocess image\n",
        "    img = load_img(image_path, target_size=(150, 150))  # Resize\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Get predicted class\n",
        "    predicted_class = class_labels[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction)\n",
        "\n",
        "    print(f\"✅ Predicted Disease: {predicted_class}\")\n",
        "\n",
        "# ✅ Step 4: Run Prediction on New Image\n",
        "image_path = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset/train/potato/late blight/0051e5e8-d1c4-4a84-bf3a-a426cdad6285___RS_LB 4640.JPG\"  # Update file path\n",
        "predict_disease(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dolec5S7GUPk",
        "outputId": "491529fb-31f6-4cdb-bb32-e9af3bf9a933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Symptoms saved successfully in /content/drive/MyDrive/under leaf spots/final dataset/dataset/symptoms.txt\n",
            "✅ Remedies saved successfully in /content/drive/MyDrive/under leaf spots/final dataset/dataset/remedies.txt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define crop disease dataset path (Modify this based on your actual dataset)\n",
        "dataset_path = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset\"\n",
        "\n",
        "# Create a dictionary with symptoms and remedies\n",
        "crop_disease_info = {\n",
        "    \"Potato_Late_Blight\": {\n",
        "        \"symptoms\": \"Small, light to dark green, circular or irregular-shaped spots on leaves.\",\n",
        "        \"remedies\": \"Use disease-free tubers for planting,Use fungicides such as Ridomil Gold,Remove and destroy infected plants.\"\n",
        "    },\n",
        "    \"Rice_Leaf_Blast\": {\n",
        "        \"symptoms\": \"Elliptical spots on leaves with light centers and reddish edges,Death of seedlings or young plants.\",\n",
        "        \"remedies\": \"Use a broad-spectrum seed treatment,Avoid excessive nitrogen application.\"\n",
        "    },\n",
        "    \"Tomato_Yellow_Leaf_Curl_Virus\": {\n",
        "        \"symptoms\": \"Yellowing and curling of leaves, reduced fruit production.\",\n",
        "        \"remedies\": \"Control whiteflies using insecticides, use resistant tomato varieties.\"\n",
        "    },\n",
        "    \"Tomato_Target_Spot\": {\n",
        "        \"symptoms\": \"Irregular-shaped spots with a yellow margin,Spots on the stems.\",\n",
        "        \"remedies\": \"Use fungicides like chlorothalonil, copper oxychloride, or mancozeb,Don't plant tomatoes near old plantings.\"\n",
        "    },\n",
        "    \"Healthy\": {\n",
        "        \"symptoms\": \"No disease detected.\",\n",
        "        \"remedies\": \"No action needed.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# File paths for storing symptoms and remedies\n",
        "symptoms_file = os.path.join(dataset_path, \"symptoms.txt\")\n",
        "remedies_file = os.path.join(dataset_path, \"remedies.txt\")\n",
        "\n",
        "# Write Symptoms to a file\n",
        "with open(symptoms_file, \"w\") as symp_file:\n",
        "    for disease, details in crop_disease_info.items():\n",
        "        symp_file.write(f\"{disease}: {details['symptoms']}\\n\")\n",
        "\n",
        "print(f\"✅ Symptoms saved successfully in {symptoms_file}\")\n",
        "\n",
        "# Write Remedies to a file\n",
        "with open(remedies_file, \"w\") as rem_file:\n",
        "    for disease, details in crop_disease_info.items():\n",
        "        rem_file.write(f\"{disease}: {details['remedies']}\\n\")\n",
        "\n",
        "print(f\"✅ Remedies saved successfully in {remedies_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8ZWsYk3K-Zm",
        "outputId": "327bdd15-24af-413f-a8d0-913796cf5a55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
            "\n",
            "🌱 *Crop Disease Detected*:  Potato_Late_Blight\n",
            "🩺 *Symptoms*:  Small, light to dark green, circular or irregular-shaped spots on leaves.\n",
            "💊 *Remedies*:  Use disease-free tubers for planting,Use fungicides such as Ridomil Gold,Remove and destroy infected plants.\n",
            "\n",
            "✅ Disease details saved in: /content/drive/MyDrive/Results.txt\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "\n",
        "# Load trained model\n",
        "model_path = \"/content/drive/MyDrive/under leaf spots/crop_disease_model.keras\"  # Update with actual path\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# File paths for symptoms and remedies\n",
        "symptoms_file = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset/symptoms.txt\"  # Update with actual path\n",
        "remedies_file = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset/remedies.txt\"  # Update with actual path\n",
        "\n",
        "# Function to load symptoms and remedies from files\n",
        "def load_data(file_path):\n",
        "    disease_info = {}\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split(\":\", 1)  # Splitting disease and info\n",
        "            if len(parts) == 2:\n",
        "                disease_name, details = parts\n",
        "                disease_info[disease_name.strip()] = details.strip()\n",
        "    return disease_info\n",
        "\n",
        "# Load symptoms and remedies data\n",
        "symptoms_data = load_data(symptoms_file)\n",
        "remedies_data = load_data(remedies_file)\n",
        "\n",
        "# Function to predict crop disease from an image\n",
        "def predict_disease(image_path):\n",
        "    img_size = (150, 150)  # Ensure this matches the model input size\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    img = load_img(image_path, target_size=img_size)\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Get class labels (Ensure your trained model's labels match)\n",
        "    class_labels = list(symptoms_data.keys())  # Using symptom file keys as labels\n",
        "    predicted_class = class_labels[np.argmax(prediction)]\n",
        "\n",
        "    # Retrieve symptoms and remedies\n",
        "    symptoms = symptoms_data.get(predicted_class, \"No symptoms found\")\n",
        "    remedies = remedies_data.get(predicted_class, \"No remedies found\")\n",
        "\n",
        "    # Print output\n",
        "    print(\"\\n🌱 *Crop Disease Detected*: \", predicted_class)\n",
        "    print(\"🩺 *Symptoms*: \", symptoms)\n",
        "    print(\"💊 *Remedies*: \", remedies)\n",
        "\n",
        "    # Save results to a text file\n",
        "    output_file = \"/content/drive/MyDrive/Results.txt\"  # Update path\n",
        "    with open(output_file, \"w\") as file:\n",
        "        file.write(f\"Crop Disease: {predicted_class}\\n\")\n",
        "        file.write(f\"Symptoms: {symptoms}\\n\")\n",
        "        file.write(f\"Remedies: {remedies}\\n\")\n",
        "\n",
        "    print(f\"\\n✅ Disease details saved in: {output_file}\")\n",
        "\n",
        "# 📌 Provide the path to the image you want to test\n",
        "image_path = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset/train/potato/late blight/0051e5e8-d1c4-4a84-bf3a-a426cdad6285___RS_LB 4640.JPG\"  # Update with actual image path\n",
        "\n",
        "# Call the function to predict and display results\n",
        "predict_disease(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMma2yCs0u1H",
        "outputId": "d9e7ea58-5fec-43ce-a53d-aba1d549619a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import os\n",
        "\n",
        "# Load the trained model\n",
        "model_path = \"/content/drive/MyDrive/under leaf spots/crop_disease_model.keras\"  # Update path\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Load symptoms and remedies data\n",
        "def load_text_file(file_path):\n",
        "    disease_info = {}\n",
        "    with open(file_path, \"r\") as file:\n",
        "        for line in file.readlines():\n",
        "            parts = line.strip().split(\":\", 1)\n",
        "            if len(parts) == 2:\n",
        "                disease_info[parts[0].strip()] = parts[1].strip()\n",
        "    return disease_info\n",
        "\n",
        "# Update file paths\n",
        "symptoms_file = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset/symptoms.txt\"\n",
        "remedies_file = \"/content/drive/MyDrive/under leaf spots/final dataset/dataset/remedies.txt\"\n",
        "\n",
        "symptoms_data = load_text_file(symptoms_file)\n",
        "remedies_data = load_text_file(remedies_file)\n",
        "\n",
        "# Function to predict crop disease\n",
        "def predict_disease(image_path):\n",
        "    img_size = (150, 150)  # Ensure it matches the model input size\n",
        "\n",
        "    # Load and preprocess image\n",
        "    img = load_img(image_path, target_size=img_size)\n",
        "    img_array = img_to_array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Get class labels from symptoms file\n",
        "    class_labels = list(symptoms_data.keys())  # Using symptom file keys as labels\n",
        "    predicted_class = class_labels[np.argmax(prediction)]\n",
        "\n",
        "    return predicted_class\n",
        "\n",
        "# Streamlit UI\n",
        "def main():\n",
        "    st.title(\"🌿 Crop Disease Detection App\")\n",
        "    st.write(\"Upload an image to detect the disease and get remedies!\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        st.image(uploaded_file, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "        # Save uploaded image\n",
        "        image_path = \"uploaded_image.jpg\"\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(uploaded_file.getbuffer())\n",
        "\n",
        "        # Predict disease\n",
        "        disease_name = predict_disease(image_path)\n",
        "\n",
        "        # Retrieve symptoms and remedies\n",
        "        symptoms = symptoms_data.get(disease_name, \"No symptoms found\")\n",
        "        remedies = remedies_data.get(disease_name, \"No remedies found\")\n",
        "\n",
        "        # Display results\n",
        "        st.subheader(f\"🦠 Disease Identified: {disease_name}\")\n",
        "        st.write(f\"📝 Symptoms: {symptoms}\")\n",
        "        st.write(f\"💊 Remedies: {remedies}\")\n",
        "\n",
        "        st.success(\"✅ Analysis Completed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AVswUCSx6BUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43c4195-964f-43c0-e61a-f6740a1e3288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.27.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.42.2 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze> requirements.txt"
      ],
      "metadata": {
        "id": "y7oVQckJQguh"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1-j3Sj9tPgajJ4jYNNOlRSdzcRbX0S7O1",
      "authorship_tag": "ABX9TyPd+RTuci3XDsmNgxOiQuCM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}